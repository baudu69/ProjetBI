{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(threshold=10000,suppress=True)\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "warnings.filterwarnings('ignore')\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Traitement des données de base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def traitementCSVTemperature(fichier : str):\n",
    "    data = pd.read_csv(fichier,sep=';', header=0)\n",
    "    data = data[['numer_sta','date','t']]\n",
    "    data['date'] = pd.to_datetime(data['date'], format='%Y%m%d%H%M%S', utc=True)\n",
    "    data['heure'] = data['date'].dt.hour\n",
    "    data['date'] = data['date'].dt.date\n",
    "    #On enlève les stations qui n'ont pas un ID entre 7000 et 8000 (outre-mer)\n",
    "    data = data[data['numer_sta'] >= 7000]\n",
    "    data = data[data['numer_sta'] <= 8000]\n",
    "    data = data[data['t'] != 'mq']\n",
    "    data['t'] = data['t'].astype(float)\n",
    "    data['t'] = data['t'] - 273.15\n",
    "    data = data.groupby(['date','heure','numer_sta']).mean()\n",
    "    data = data.groupby(['date','heure']).mean()\n",
    "    data.reset_index(inplace=True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def traitementCSVConsomation(fichier : str):\n",
    "    rte = pd.read_csv(fichier,sep=';', header=0)\n",
    "    rte['Date'] = pd.to_datetime(rte['Date'], dayfirst=True)\n",
    "    rte['Date'] = rte['Date'].dt.date\n",
    "    rte = rte[rte['Heures'].str.endswith('00')]\n",
    "    rte['Heures'] = rte['Heures'].str.slice(0,2)\n",
    "    rte['Heures'] = rte['Heures'].astype(int)\n",
    "    return rte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def fusionData(rte : pd.DataFrame, temperature : pd.DataFrame):\n",
    "    data = pd.merge(rte,temperature,how='inner',left_on=['Date','Heures'],right_on=['date','heure'])\n",
    "    data = data.drop(['date','heure'],axis=1)\n",
    "    data = data.dropna()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def traitementAllCSVTemperatures(fichiers : list[str]):\n",
    "    data = pd.DataFrame()\n",
    "    for fichier in fichiers:\n",
    "        temp = traitementCSVTemperature(fichier)\n",
    "        data = pd.concat([data,temp])\n",
    "    data = data.groupby(['date','heure']).mean()\n",
    "    data.reset_index(inplace=True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fichiers_temperature = []\n",
    "for annee in [2015, 2016, 2017, 2018, 2019]:\n",
    "    for mois in range(1,13):\n",
    "        if mois < 10:\n",
    "            fichiers_temperature.append('temperatures/synop.'+str(annee)+'0'+str(mois)+'.csv')\n",
    "        else:\n",
    "            fichiers_temperature.append('temperatures/synop.'+str(annee)+str(mois)+'.csv')\n",
    "temperatures = traitementAllCSVTemperatures(fichiers_temperature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rte  = pd.DataFrame()\n",
    "for annee in [2015, 2016, 2017, 2018, 2019]:\n",
    "    rte = pd.concat([rte, traitementCSVConsomation('rte_'+str(annee)+'.csv')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_total = fusionData(rte,temperatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_total.to_csv('data_total.csv',index=False, sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Traitement des données pour apprentissage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def ajouterJourSemaine(data : pd.DataFrame):\n",
    "    data['Date'] = pd.to_datetime(data['Date'], format='%Y-%m-%d')\n",
    "    data['jour_semaine'] = data['Date'].dt.dayofweek\n",
    "    data['jour_mois'] = data['Date'].dt.day\n",
    "    data['mois'] = data['Date'].dt.month\n",
    "    return data\n",
    "\n",
    "def enleverDate(data : pd.DataFrame):\n",
    "    data = data.drop(['Date'],axis=1)\n",
    "    return data\n",
    "\n",
    "\n",
    "def swap_consommation(df : pd.DataFrame):\n",
    "    col_list = list(df.columns)\n",
    "    x, y = col_list.index('Consommation'), col_list.index(df.columns[len(df.columns)-1])\n",
    "    col_list[y], col_list[x] = col_list[x], col_list[y]\n",
    "    df = df[col_list]\n",
    "    return df\n",
    "\n",
    "\n",
    "#On met la colonne 'Consommation' en dernière position\n",
    "\n",
    "data_apprentissage = ajouterJourSemaine(data_total)\n",
    "data_apprentissage = enleverDate(data_apprentissage)\n",
    "data_apprentissage = swap_consommation(data_apprentissage)\n",
    "\n",
    "data_apprentissage.to_csv('data_apprentissage_2018.csv',index=False, sep=';')\n",
    "data_apprentissage.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x = data_apprentissage.iloc[:, :-1].values\n",
    "y = data_apprentissage.iloc[:, -1].values\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class DataLoader(object):\n",
    "    def __init__(self, x : np.ndarray, y : np.ndarray, batch_size=128, shuffle=True):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.start_idx = 0\n",
    "        self.data_size = x.shape[0]\n",
    "        if self.shuffle:\n",
    "            self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.x, self.y = shuffle(self.x, self.y, random_state=1)\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        if self.start_idx >= self.data_size:\n",
    "            if self.shuffle:\n",
    "                self.reset()\n",
    "            self.start_idx = 0\n",
    "            raise StopIteration\n",
    "\n",
    "        batch_x = self.x[self.start_idx:][:self.batch_size]\n",
    "        batch_y = self.y[self.start_idx:][:self.batch_size]\n",
    "\n",
    "        batch_x = torch.tensor(batch_x, dtype=torch.float, device=device)\n",
    "        batch_y = torch.tensor(batch_y, dtype=torch.float, device=device)\n",
    "\n",
    "        self.start_idx += self.batch_size\n",
    "\n",
    "        return batch_x, batch_y\n",
    "\n",
    "# class MLP(torch.nn.Module):\n",
    "#     def __init__(self, in_dim : int, caches : list[int], out_dim : int = 1):\n",
    "#         super(MLP, self).__init__()\n",
    "\n",
    "#         assert out_dim==1, 'out_dim must be 1'\n",
    "#         self.in_dim = in_dim\n",
    "#         self.out_dim = out_dim\n",
    "#         self.couches = torch.nn.ModuleList()\n",
    "#         for i in range(len(caches)):\n",
    "#             self.couches.append(torch.nn.Linear(self.in_dim if i == 0 else caches[i-1], caches[i]))\n",
    "#         self.couches.append(torch.nn.Linear(caches[-1], self.out_dim))\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         for i in range(len(self.couches)):\n",
    "#             x = torch.relu(self.couches[i](x))\n",
    "#         x=torch.squeeze(x)\n",
    "#         return x\n",
    "    \n",
    "def MLP(in_dim : int, caches : list[int], out_dim : int = 1):\n",
    "    assert out_dim==1, 'out_dim must be 1'\n",
    "    couches = []\n",
    "    for i in range(len(caches)):\n",
    "        couches.append(torch.nn.Linear(in_dim if i == 0 else caches[i-1], caches[i]))\n",
    "        couches.append(torch.nn.ReLU())\n",
    "    couches.append(torch.nn.Linear(caches[-1], out_dim))\n",
    "    couches.append(torch.nn.ReLU())\n",
    "    couches.append(torch.nn.Flatten())\n",
    "    return torch.nn.Sequential(*couches)\n",
    "\n",
    "def mae_loss(y_pred : np.ndarray, y_true : np.ndarray):\n",
    "    mae = torch.abs(y_true - y_pred).mean()\n",
    "    return mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(x_train, y_train, batch_size=4000)\n",
    "valid_dataloader = DataLoader(x_test, y_test, batch_size=4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def fit(epochs : int = 200, learning_rate : float = 0.1, couche : list[int] = None, show_loss : bool = True):\n",
    "    mlp = MLP(x_train[0].shape[0], couche, 1)\n",
    "    mlp.to(device)\n",
    "    optimizer = torch.optim.Adam(mlp.parameters(), lr=learning_rate)\n",
    "    best_loss = np.inf\n",
    "    valid_losses = []\n",
    "    for epoch in range(epochs):\n",
    "        mlp.train()\n",
    "        for batch_id, (batch_x, batch_y) in enumerate(train_dataloader):\n",
    "            y_pred = mlp(batch_x)\n",
    "            loss = mae_loss(y_pred, batch_y)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        mlp.eval()\n",
    "        valid_loss = 0\n",
    "        num_batch = valid_dataloader.data_size // valid_dataloader.batch_size + 1\n",
    "\n",
    "        for batch_id, (batch_x, batch_y) in enumerate(valid_dataloader):\n",
    "\n",
    "            y_pred = mlp(batch_x)\n",
    "            loss = mae_loss(y_pred, batch_y)\n",
    "            valid_loss += loss.item()\n",
    "\n",
    "        valid_loss /= num_batch\n",
    "        valid_losses.append(valid_loss)\n",
    "\n",
    "        if valid_loss < best_loss:\n",
    "            best_loss = valid_loss\n",
    "            torch.save(mlp.state_dict(), 'mlp.model')\n",
    "    if show_loss:\n",
    "        print(\"Best Loss is \" + str(best_loss))\n",
    "        plt.plot(valid_losses)\n",
    "        plt.show()\n",
    "    return mlp, best_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def testParameters(couches : list[list[int]], lr : list[float], epochs : int = 10):\n",
    "    best = np.inf\n",
    "    best_parameters = None\n",
    "    for couche in couches:\n",
    "        for learning_rate in lr:\n",
    "            tot_loss = 0\n",
    "            for numero_test in range(epochs):\n",
    "                mlp, best_loss = fit(couche=couche, learning_rate=learning_rate, show_loss=False)\n",
    "                tot_loss += best_loss\n",
    "            tot_loss /= epochs\n",
    "            if tot_loss < best:\n",
    "                best = tot_loss\n",
    "                best_parameters = [couche, learning_rate]\n",
    "    return best_parameters, best\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "best_parameters, best = testParameters([[100,100,100]], [0.1], 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "best_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def predict(model : torch.nn.Module, heure : int, temperature : int, jour : int):\n",
    "    toPredict = np.array([[heure, temperature, jour]])\n",
    "    toPredict = torch.tensor(toPredict,dtype=torch.float,device=device)\n",
    "    y_pred : torch.Tensor = model(toPredict)\n",
    "    y_pred = y_pred.data.cpu().numpy()\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "best_model, score = fit(100, 0.1, [70, 70, 70], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "\n",
    "def testDate(date_str: str, model: MLP):\n",
    "    date=datetime.strptime(date_str, '%d/%m/%y')\n",
    "    jour_semaine=date.weekday()\n",
    "    jour_mois=date.day\n",
    "    mois=date.month\n",
    "    data_test = ajouterJourSemaine(data_total)\n",
    "    data_test = swap_consommation(data_test)\n",
    "    data_test=data_test[data_test['Date']==date_str]\n",
    "    data_test = enleverDate(data_test)\n",
    "    data_predict = []\n",
    "    data_test.reset_index(inplace=True)\n",
    "    for i,ligne in data_test.iterrows():\n",
    "        data_predict.append(predict(model, ligne['Heures'], ligne['t'], jour_semaine, jour_mois, mois))\n",
    "    plt.plot(data_test['Consommation'])\n",
    "    plt.plot(data_predict)\n",
    "    plt.legend(['Consommation réelle', 'Consommation estimée'])\n",
    "    plt.show()\n",
    "\n",
    "testDate('30/07/19', best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "1121f15318d0d4518cc90557bdd3cc6df359a3ea4b28c3fd3d3ecf37cc6a5f14"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
